library(parallel)
library(bmixture)
library(fields)
library(stringr)
copy = 1;
rawdata <- load(paste("Rdata/rawdata",copy,".Rdata",sep=""))
consoData<-function( Data )
{
J = nrow( Data )
N0 = ncol( Data )
C0 = rep( 0, N0 )
for ( j in 1:J ){
for ( i in 1:N0 ){
if ( sum( Data[ -j, i ] == 0 ) == ( J - 1 ) ){ C0[ i ] = j } #record invariant read position
}
}
g0 = list( NULL ) #Original indices for the consolidated sites
na.list = list( NULL )
newD = matrix( NA, nrow = J, ncol = J )
for ( j in 1:J ){
g0[[ j ]] = which( C0 == j )
l = length( which( C0 == j ) )
if ( l == 0 ){ na.list
}else if ( l == 1 ){ newD[ , j ] = Data[ , g0[[ j ]] ]
}else{ newD[ , j ] = rowSums( Data[ , g0[[ j ]] ] ) #consolidate invariant read sites
}
}
g0[[ J+1 ]] = which( C0==0 )
g0.length = lapply( g0, length )
emptyg0 = which( g0.length == 0 )
if ( length( emptyg0 ) > 0 ){ newD = newD[ , -emptyg0 ] }
newData = cbind( newD, Data[ , g0[[ J + 1 ]] ] )
return( list( newData, g0 ) )
}
conso=consoData(rawdata)
ncol( rawdata )
copy = 1;
rawdata <- load(paste0("Rdata/rawdata",copy,".Rdata",sep=""))
copy = 1;
rawdata <- load(rawdata1.Rdata)
copy = 1;
rawdata <- load(Rdata/rawdata1.Rdata)
setwd("~/Desktop/Workspace/Dirichlet-Mixture-Model")
copy = 1;
rawdata <- load(Rdata/rawdata1.Rdata)
copy = 1;
rawdata <- load('Rdata/rawdata1.Rdata')
load("~/Desktop/Workspace/Dirichlet-Mixture-Model/Rdata/rawdata1.Rdata")
copy = 1;
rawdata <- get(load('Rdata/rawdata1.Rdata'))
copy = 1;
rawdata <- load('Rdata/rawdata1.Rdata')
library(bmixture)
createtestdata<-function(K0 = 15, newK = 5, d = 5, n = 300,
sitect = 5000, tests = 4, postD = 4 )
{
PP = sapply( 1:K0, function(x){ return( NucleoProb( d ) ) } )
newPP = apply( PP[ , 1:newK ], 2, NewNucleoProb )
b = n / K0
rawdata = matrix( NA, nrow = d, ncol = tests * n ) # tests*n?
for( i in 1:K0 ){
for( t in 1:tests ){
rawdata[ , ( b * ( i - 1 ) + 1 ) : ( b * i ) + n * ( t - 1 ) ] =
rmultinom( b, sitect, PP[ , i ] )
}
}
for( i in 1:newK ){
for( t in postD ){
rawdata[ , ( b * ( i - 1 ) + 1 ) + n * ( t - 1 ) ] =
rmultinom( 1, sitect, newPP[ , i ] )
}
}
save(rawdata, PP, newPP, tests, sitect, postD,
file = paste("Rdata/rawdata",".Rdata",sep=""))
return(paste("Rawdata"," created!",sep=""))
}
NucleoProb = function( J, J.main = 4 ){
#J: number of possible reads; J.main: number of possible invariant reads
p = runif( J )
main = rep( 0, J )
r = runif(1)
if( r > .5 ){ main[ sample.int( J.main, size = 1 ) ] = 100
}else if( r > .25 ){ main[ sample.int( J.main, size = 2 ) ] = c(25, 75)
}else{ main[ sample.int( J.main, size = 2 ) ] = c(50, 50) }
newp = rdirichlet( 1, p + main )
return( newp )
}
#Let the second largest element of newp be 10, and normalize newp
NewNucleoProb = function( oldp, read.main = 4 ){
oldp.main = oldp[ 1:read.main ]
oldp.2max = which( oldp.main == sort( oldp.main, decreasing = T )[2] )
newp = oldp; newp[ oldp.2max ] = 10; newp = newp / sum( newp )
return( newp )
}
PostD = 3; K.control = 5; K.mut = 5; J = 5; n = 100; m = 500; J = 5;
createtestdata(copy, K0 = K.control, newK = K.mut, d = J, n = n, sitect = m, tests = max(PostD),
postD = PostD )
PostD = 3; K.control = 5; K.mut = 5; J = 5; n = 100; m = 500; J = 5;
createtestdata(K0 = K.control, newK = K.mut, d = J, n = n, sitect = m, tests = max(PostD),
postD = PostD )
library(coda)
library(parallel)
library(bmixture)
library(fields)
library(stringr)
load('Rdata/rawdata.Rdata')
consoData<-function( Data )
{
J = nrow( Data )
N0 = ncol( Data )
C0 = rep( 0, N0 )
for ( j in 1:J ){
for ( i in 1:N0 ){
if ( sum( Data[ -j, i ] == 0 ) == ( J - 1 ) ){ C0[ i ] = j } #record invariant read position
}
}
g0 = list( NULL ) #Original indices for the consolidated sites
na.list = list( NULL )
newD = matrix( NA, nrow = J, ncol = J )
for ( j in 1:J ){
g0[[ j ]] = which( C0 == j )
l = length( which( C0 == j ) )
if ( l == 0 ){ na.list
}else if ( l == 1 ){ newD[ , j ] = Data[ , g0[[ j ]] ]
}else{ newD[ , j ] = rowSums( Data[ , g0[[ j ]] ] ) #consolidate invariant read sites
}
}
g0[[ J+1 ]] = which( C0==0 )
g0.length = lapply( g0, length )
emptyg0 = which( g0.length == 0 )
if ( length( emptyg0 ) > 0 ){ newD = newD[ , -emptyg0 ] }
newData = cbind( newD, Data[ , g0[[ J + 1 ]] ] )
return( list( newData, g0 ) )
}
conso=consoData(rawdata)
Data=conso[[1]]
G0=conso[[2]]
save(Data,G0,file=Data)
conso=consoData(rawdata)
Data=conso[[1]]
G0=conso[[2]]
save(Data,G0,file=Data.Rdata)
conso=consoData(rawdata)
Data=conso[[1]]
G0=conso[[2]]
save(Data, G0, file = 'Data.Rdata')
library(coda)
library(parallel)
library(bmixture)
library(fields)
library(stringr)
source("library_cmdline.R")
library(coda)
library(parallel)
library(bmixture)
library(fields)
library(stringr)
source("library_cmdline.R")
set.seed(123)
load('Rdata/rawdata.Rdata')
consoData<-function( Data )
{
J = nrow( Data )
N0 = ncol( Data )
C0 = rep( 0, N0 )
for ( j in 1:J ){
for ( i in 1:N0 ){
if ( sum( Data[ -j, i ] == 0 ) == ( J - 1 ) ){ C0[ i ] = j } #record invariant read position
}
}
g0 = list( NULL ) #Original indices for the consolidated sites
na.list = list( NULL )
newD = matrix( NA, nrow = J, ncol = J )
for ( j in 1:J ){
g0[[ j ]] = which( C0 == j )
l = length( which( C0 == j ) )
if ( l == 0 ){ na.list
}else if ( l == 1 ){ newD[ , j ] = Data[ , g0[[ j ]] ]
}else{ newD[ , j ] = rowSums( Data[ , g0[[ j ]] ] ) #consolidate invariant read sites
}
}
g0[[ J+1 ]] = which( C0==0 )
g0.length = lapply( g0, length )
emptyg0 = which( g0.length == 0 )
if ( length( emptyg0 ) > 0 ){ newD = newD[ , -emptyg0 ] }
newData = cbind( newD, Data[ , g0[[ J + 1 ]] ] )
return( list( newData, g0 ) )
}
conso=consoData(rawdata)
Data=conso[[1]]
G0=conso[[2]]
save(Data, G0, file = 'Data.Rdata')
current<-cmdline.numeric("current")
cmdline.numeric("current")
load('Rdata/rawdata.Rdata')
## change here maximum of K and a
inf_sum_approx <- function(u, K, N, L) {
r = seq(u, max(u,K))
results = r * log(L) - L - lgamma(r - u + 1) - N * log(r)
return(logSumExp(results, na.rm = TRUE))
}
LP_Emma <- function(Y, C, K, a, L = 10) #a is the even weight in the Dirichlet prior, whose concentration=5a.
{
J = nrow(Y)
u = length(unique(C))
Vec = rep(0, u)
### Case 1: Y is a vector (we are at the end of the tree)
if (is.null(dim(Y)) == TRUE) {
#lp = sum(lgamma(Y + (1 / J ^ 2))) - lgamma(sum(Y)+(1/J)) + inf_sum_approx(a = 1, N = 1, L) + lgamma(1 / J) - J * lgamma(1 / J ^ 2)
print("ERROR Y US A VECTOR")
}
### Case 2: Y is a matrix
else{
for (k in unique(C)) #k in unique C
{
I = which(C == k)
#Case 2.1: I is empty
if (length(I) == 0){
#Vec[k] = J * lgamma(1 / J ^ 2) - lgamma(1 / J)
print("ERROR I EMPTY")
}
#Case 2.2: I contains one number
if (length(I) == 1) {
Vec[k] = sum(lgamma( Y[, I] + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
}
#Case 2.3: I is a set of numbers
else{
Vec[k] = sum(lgamma(rowSums(Y[, I]) + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
#change here second lgamma should be a real number
}
}
lp = sum(Vec) + inf_sum_approx(u, K, N, L) + u * lgamma(1 / J) - J * u *
lgamma(1 / J ^ 2)
}
return(lp)
}
a = "help"
N = ncol(Data)
Y = Data
C = kmeans(t(Y),2)[[1]]
K = 2
LP_Emma(Y, C, K, a, L = 10)
library(matrixStats)
load('Rdata/rawdata.Rdata')
## change here maximum of K and a
inf_sum_approx <- function(u, K, N, L) {
r = seq(u, max(u,K))
results = r * log(L) - L - lgamma(r - u + 1) - N * log(r)
return(logSumExp(results, na.rm = TRUE))
}
LP_Emma <- function(Y, C, K, a, L = 10) #a is the even weight in the Dirichlet prior, whose concentration=5a.
{
J = nrow(Y)
u = length(unique(C))
Vec = rep(0, u)
### Case 1: Y is a vector (we are at the end of the tree)
if (is.null(dim(Y)) == TRUE) {
#lp = sum(lgamma(Y + (1 / J ^ 2))) - lgamma(sum(Y)+(1/J)) + inf_sum_approx(a = 1, N = 1, L) + lgamma(1 / J) - J * lgamma(1 / J ^ 2)
print("ERROR Y US A VECTOR")
}
### Case 2: Y is a matrix
else{
for (k in unique(C)) #k in unique C
{
I = which(C == k)
#Case 2.1: I is empty
if (length(I) == 0){
#Vec[k] = J * lgamma(1 / J ^ 2) - lgamma(1 / J)
print("ERROR I EMPTY")
}
#Case 2.2: I contains one number
if (length(I) == 1) {
Vec[k] = sum(lgamma( Y[, I] + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
}
#Case 2.3: I is a set of numbers
else{
Vec[k] = sum(lgamma(rowSums(Y[, I]) + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
#change here second lgamma should be a real number
}
}
lp = sum(Vec) + inf_sum_approx(u, K, N, L) + u * lgamma(1 / J) - J * u *
lgamma(1 / J ^ 2)
}
return(lp)
}
a = "help"
N = ncol(Data)
Y = Data
C = kmeans(t(Y),2)[[1]]
K = 2
LP_Emma(Y, C, K, a, L = 10)
library(matrixStats)
#load('Rdata/rawdata.Rdata')
Data = data.frame(c(1,1,1),c(2,2,2))
## change here maximum of K and a
inf_sum_approx <- function(u, K, N, L) {
r = seq(u, max(u,K))
results = r * log(L) - L - lgamma(r - u + 1) - N * log(r)
return(logSumExp(results, na.rm = TRUE))
}
LP_Emma <- function(Y, C, K, a, L = 10) #a is the even weight in the Dirichlet prior, whose concentration=5a.
{
J = nrow(Y)
u = length(unique(C))
Vec = rep(0, u)
### Case 1: Y is a vector (we are at the end of the tree)
if (is.null(dim(Y)) == TRUE) {
#lp = sum(lgamma(Y + (1 / J ^ 2))) - lgamma(sum(Y)+(1/J)) + inf_sum_approx(a = 1, N = 1, L) + lgamma(1 / J) - J * lgamma(1 / J ^ 2)
print("ERROR Y US A VECTOR")
}
### Case 2: Y is a matrix
else{
for (k in unique(C)) #k in unique C
{
I = which(C == k)
#Case 2.1: I is empty
if (length(I) == 0){
#Vec[k] = J * lgamma(1 / J ^ 2) - lgamma(1 / J)
print("ERROR I EMPTY")
}
#Case 2.2: I contains one number
if (length(I) == 1) {
Vec[k] = sum(lgamma( Y[, I] + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
}
#Case 2.3: I is a set of numbers
else{
Vec[k] = sum(lgamma(rowSums(Y[, I]) + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
#change here second lgamma should be a real number
}
}
lp = sum(Vec) + inf_sum_approx(u, K, N, L) + u * lgamma(1 / J) - J * u *
lgamma(1 / J ^ 2)
}
return(lp)
}
a = "help"
N = ncol(Data)
Y = Data
C = kmeans(t(Y),2)[[1]]
library(matrixStats)
#load('Rdata/rawdata.Rdata')
Data = data.frame(c(1,1,1),c(1,2,3))
## change here maximum of K and a
inf_sum_approx <- function(u, K, N, L) {
r = seq(u, max(u,K))
results = r * log(L) - L - lgamma(r - u + 1) - N * log(r)
return(logSumExp(results, na.rm = TRUE))
}
LP_Emma <- function(Y, C, K, a, L = 10) #a is the even weight in the Dirichlet prior, whose concentration=5a.
{
J = nrow(Y)
u = length(unique(C))
Vec = rep(0, u)
### Case 1: Y is a vector (we are at the end of the tree)
if (is.null(dim(Y)) == TRUE) {
#lp = sum(lgamma(Y + (1 / J ^ 2))) - lgamma(sum(Y)+(1/J)) + inf_sum_approx(a = 1, N = 1, L) + lgamma(1 / J) - J * lgamma(1 / J ^ 2)
print("ERROR Y US A VECTOR")
}
### Case 2: Y is a matrix
else{
for (k in unique(C)) #k in unique C
{
I = which(C == k)
#Case 2.1: I is empty
if (length(I) == 0){
#Vec[k] = J * lgamma(1 / J ^ 2) - lgamma(1 / J)
print("ERROR I EMPTY")
}
#Case 2.2: I contains one number
if (length(I) == 1) {
Vec[k] = sum(lgamma( Y[, I] + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
}
#Case 2.3: I is a set of numbers
else{
Vec[k] = sum(lgamma(rowSums(Y[, I]) + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
#change here second lgamma should be a real number
}
}
lp = sum(Vec) + inf_sum_approx(u, K, N, L) + u * lgamma(1 / J) - J * u *
lgamma(1 / J ^ 2)
}
return(lp)
}
a = "help"
N = ncol(Data)
Y = Data
C = kmeans(t(Y),2)[[1]]
library(matrixStats)
#load('Rdata/rawdata.Rdata')
Data = data.frame(c(0,0,0),c(1,2,3))
## change here maximum of K and a
inf_sum_approx <- function(u, K, N, L) {
r = seq(u, max(u,K))
results = r * log(L) - L - lgamma(r - u + 1) - N * log(r)
return(logSumExp(results, na.rm = TRUE))
}
LP_Emma <- function(Y, C, K, a, L = 10) #a is the even weight in the Dirichlet prior, whose concentration=5a.
{
J = nrow(Y)
u = length(unique(C))
Vec = rep(0, u)
### Case 1: Y is a vector (we are at the end of the tree)
if (is.null(dim(Y)) == TRUE) {
#lp = sum(lgamma(Y + (1 / J ^ 2))) - lgamma(sum(Y)+(1/J)) + inf_sum_approx(a = 1, N = 1, L) + lgamma(1 / J) - J * lgamma(1 / J ^ 2)
print("ERROR Y US A VECTOR")
}
### Case 2: Y is a matrix
else{
for (k in unique(C)) #k in unique C
{
I = which(C == k)
#Case 2.1: I is empty
if (length(I) == 0){
#Vec[k] = J * lgamma(1 / J ^ 2) - lgamma(1 / J)
print("ERROR I EMPTY")
}
#Case 2.2: I contains one number
if (length(I) == 1) {
Vec[k] = sum(lgamma( Y[, I] + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
}
#Case 2.3: I is a set of numbers
else{
Vec[k] = sum(lgamma(rowSums(Y[, I]) + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
#change here second lgamma should be a real number
}
}
lp = sum(Vec) + inf_sum_approx(u, K, N, L) + u * lgamma(1 / J) - J * u *
lgamma(1 / J ^ 2)
}
return(lp)
}
a = "help"
N = ncol(Data)
Y = Data
C = kmeans(t(Y),2)[[1]]
library(matrixStats)
#load('Rdata/rawdata.Rdata')
Data = data.frame(c(0,0,0),c(1,2,3),c(1,1,1))
## change here maximum of K and a
inf_sum_approx <- function(u, K, N, L) {
r = seq(u, max(u,K))
results = r * log(L) - L - lgamma(r - u + 1) - N * log(r)
return(logSumExp(results, na.rm = TRUE))
}
LP_Emma <- function(Y, C, K, a, L = 10) #a is the even weight in the Dirichlet prior, whose concentration=5a.
{
J = nrow(Y)
u = length(unique(C))
Vec = rep(0, u)
### Case 1: Y is a vector (we are at the end of the tree)
if (is.null(dim(Y)) == TRUE) {
#lp = sum(lgamma(Y + (1 / J ^ 2))) - lgamma(sum(Y)+(1/J)) + inf_sum_approx(a = 1, N = 1, L) + lgamma(1 / J) - J * lgamma(1 / J ^ 2)
print("ERROR Y US A VECTOR")
}
### Case 2: Y is a matrix
else{
for (k in unique(C)) #k in unique C
{
I = which(C == k)
#Case 2.1: I is empty
if (length(I) == 0){
#Vec[k] = J * lgamma(1 / J ^ 2) - lgamma(1 / J)
print("ERROR I EMPTY")
}
#Case 2.2: I contains one number
if (length(I) == 1) {
Vec[k] = sum(lgamma( Y[, I] + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
}
#Case 2.3: I is a set of numbers
else{
Vec[k] = sum(lgamma(rowSums(Y[, I]) + (1 / J ^ 2))) - lgamma(sum(Y[, I]) +
(1 / J))
#change here second lgamma should be a real number
}
}
lp = sum(Vec) + inf_sum_approx(u, K, N, L) + u * lgamma(1 / J) - J * u *
lgamma(1 / J ^ 2)
}
return(lp)
}
a = "help"
N = ncol(Data)
Y = Data
C = kmeans(t(Y),2)[[1]]
K = 2
LP_Emma(Y, C, K, a, L = 10)
library(matrixStats)
#load('Rdata/rawdata.Rdata')
Data = data.frame(c(0,0,0),c(1,2,3),c(1,1,1))
Data
a = "help"
N = ncol(Data)
N
Y = Data
Y
C = kmeans(t(Y),2)[[1]]
C
K = 2
K
LP_Emma(Y, C, K, a, L = 10)
C
